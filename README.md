# Deep Topology Learning (DeToL)

Deep Learning, i.e. deep neural networks (DNN), have 
become a key technology in recent years. However, the design of new, 
problem specific network topologies is still a time and compute 
intensive process. So far, the design of deep learning solutions for 
specific applications mostly follows a purely heuristic try and error 
process based on human expert knowledge and experience. Every network 
topology needs to be built from a large number of layer types and their 
configuration. Most layers themselves, as well as the employed training 
methods, have complex parameter spaces (so-called hyperparameters), 
whose impact on the final DNN performance is as large as the impact of 
the network topology itself.

In this project, we aim at facilitating a more efficient topology design 
process, rendering DNNs accessible to unexperienced users. Within this 
project, besides the management and organizational tasks, me and my 
group have the task to design and evaluate suitable graph embeddings 
that facilitate to explore the network topology space in an efficient way.

**DeToL** is funded by BMBF. Runtime: October 2018 - September 2021.

## Partners

![](2000px-Uni-mannheim.svg.png )
![https://www.itwm.fraunhofer.de/de/abteilungen/hpc/Daten-Analyse-Maschinelles-Lernen.html](Fraunhofer_ITWM.jpg) 
![](lrz_wortbild_d_blau-230.png) 
![](psiori-logo-white-pix.png)
![](2000px-Albert-Ludwigs-Universität_Freiburg_2009_logo.svg.png) 

## Publications
* [Ying, C., Klein, A., Real, E., Christiansen, E., Murphy, K., & Hutter, F. (2019). NAS-Bench-101: Towards Reproducible Neural Architecture Search. arXiv preprint arXiv:1902.09635.](https://arxiv.org/abs/1902.09635)
* [Ram, R., Müller, S., Pfreundt, F. J., Gauger, N. R., & Keuper, J. (2019, November). Scalable Hyperparameter Optimization with Lazy Gaussian Processes. In 2019 IEEE/ACM Workshop on Machine Learning in High Performance Computing Environments (MLHPC) (pp. 56-65). IEEE.](https://arxiv.org/pdf/2001.05726) - **[Source Code](https://github.com/cc-hpc-itwm/HPO_LazyGPR)**
* [Habelitz, P. M., & Keuper, J. (2020). PHS: A Toolbox for Parellel Hyperparameter Search. arXiv preprint arXiv:2002.11429.](https://arxiv.org/pdf/2002.11429) - **[Source Code](https://github.com/cc-hpc-itwm/PHS)**
* [Zela, A., Elsken, T., Saikia, T., Marrakchi, Y., Brox, T., & Hutter, F. (2020). Understanding and Robustifying Differentiable Architecture Search. In International Conference on Learning Representations 2020.](https://arxiv.org/abs/1909.09656) - **[Source Code](https://github.com/automl/RobustDARTS)**
* [Zela, A., Siems, J., & Hutter, F. (2020). NAS-Bench-1Shot1; Benchmarking and Dissecting One-shot Neural Architecture Search. In International Conference on Learning Representations 2020.](https://arxiv.org/abs/2001.10422) - **[Source Code](https://github.com/automl/nasbench-1shot1)**


## Open Source Software
* -tba-

## Open Data
+ -tba-

## Contact
info@detol.de
